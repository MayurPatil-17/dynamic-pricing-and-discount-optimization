# -*- coding: utf-8 -*-
"""retail_price.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bTISD4NESiW6hsggOWhNSNNXshYWOZvV

### **Loading a CSV file and standardizing date formats for analysis in SQL.**
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
from datetime import datetime

df = pd.read_csv('data.csv', encoding='cp1252')
df.head(10)

def fix_date(date_str):
  if pd.isna(date_str):
    return None

  s = str(date_str).strip()
  s = s.split('+')[0].split(',')[0]

  # List of possible date/time formats
  formats = [
      "%d-%m-%Y", "%m-%d-%Y", "%Y-%m-%d", "%d/%m/%Y", "%m/%d/%Y",
      "%d-%m-%Y %H:%M", "%d-%m-%Y %H:%M:%S",
      "%m-%d-%Y %H:%M", "%m-%d-%Y %H:%M:%S",
      "%Y-%m-%d %H:%M", "%Y-%m-%d %H:%M:%S",
      "%d/%m/%Y %H:%M", "%d/%m/%Y %H:%M:%S",
      "%m/%d/%Y %H:%M", "%m/%d/%Y %H:%M:%S",
      "%d-%b-%Y", "%d-%b-%Y %H:%M:%S", "%d-%b-%Y %H:%M",
      "%d/%b/%Y", "%d/%b/%Y %H:%M:%S", "%d/%b/%Y %H:%M",
      "%d-%m-%y", "%m-%d-%y", "%Y-%m-%d %H:%M:%S",
      "%d-%m-%y %H:%M:%S", "%m-%d-%y %H:%M:%S"
    ]

  for fmt in formats:
    try:
      date_obj = datetime.strptime(s, fmt)
      return date_obj.strftime("%Y-%m-%d %H:%M:%S")
    except ValueError:
      continue

  return None

df['InvoiceDate'] = df['InvoiceDate'].apply(fix_date)

# Getting the Invalid date format counts for debugging
invalid_count = df['InvoiceDate'].isna().sum()
print(f"⚠️ {invalid_count} unrecognized date/time values out of {len(df)} rows.")

df['CustomerID'] = df['CustomerID'].fillna('NULL')

print(df['CustomerID'].isna().sum())

print(df['InvoiceDate'].head(10))

# downloading the file to analyze further in SQL
output_file = "data_clean.csv"
df.to_csv(output_file, index=False)
files.download(output_file)

print("✅ Done! Dates and times standardized (YYYY-MM-DD HH:MM:SS).")

"""# **Working On our main Data**"""

from google.colab import files
uploaded = files.upload()

# Importing Fundamental Libraries for Data Analysis
import pandas as pd
import numpy as np

retail_df = pd.read_csv('sales_data_enriched.csv')
retail_df.head(10)

retail_df.info()

"""##### **Data Cleaning — Correcting Data Types and Removing Duplicates**"""

# Handle missing CustomerID
missing = retail_df['CustomerID'].isna()
max_id = int(retail_df['CustomerID'].max())
retail_df.loc[missing, 'CustomerID'] = np.arange(max_id + 1, max_id + 1 + missing.sum())

retail_df['CustomerID'].nunique()

# Correcting the data type
retail_df['CustomerID'] = retail_df['CustomerID'].astype(int)
retail_df['InvoiceDate'] = pd.to_datetime(retail_df['InvoiceDate'],format='mixed', dayfirst=True)

# dropping potential duplicates if any exists
retail_df.drop_duplicates(inplace=True)

# Extract datetime features
retail_df['Month'] = retail_df['InvoiceDate'].dt.month
retail_df['Day'] = retail_df['InvoiceDate'].dt.day
retail_df['WeekDay'] = retail_df['InvoiceDate'].dt.day_name()
retail_df['Hour'] = retail_df['InvoiceDate'].dt.hour

retail_df = retail_df[(retail_df['Quantity'] > 0) & (retail_df['UnitPrice'] > 0)]

retail_df

print("\n✅ Data Cleaning Completed!")
print("Remaining rows:", len(retail_df))

"""##### **Machine Learning in Action**"""

# Importing Essential Machine Learning Libraries
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

features = ['TotalSales', 'Profit', 'ProfitMargin', 'Discount']
X = retail_df[features].copy()

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

inertia = []
K_range = range(2, 11)

for k in K_range:
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(X_scaled)
    inertia.append(km.inertia_)

plt.figure(figsize=(8,4))
plt.plot(K_range, inertia, marker='o')
plt.title("Elbow Method - Optimal K")
plt.xlabel("Number of clusters (K)")
plt.ylabel("Inertia")
plt.show()

# 8️⃣ Apply K-Means Clustering (let’s pick K=4 as a starting point)
kmeans = KMeans(n_clusters=4, random_state=42)
retail_df['Cluster'] = kmeans.fit_predict(X_scaled)
print("✅ Clustering Completed!")

# 9️⃣ Analyze Cluster Profiles
cluster_summary = retail_df.groupby('Cluster')[features].mean().round(2)
print("\n--- Cluster Summary ---")
print(cluster_summary)